WHAT IS THIS FOLDER?
====================

This folder is basically a placeholder containing a lot of notes I've pulled from various Obsidian Portal wiki pages and Google Docs that I've written.

I've been experimenting with training ChatGPT threads on things like generating vows, creating NPC names along with interesting information, writing in-universe primary source documents based on my own notes, etc.

An interesting limitation of ChatGPT is that even within a single conversation it has a relatively narrow memory of what you've been talking about.

That's kind of strange because one of the most impressive things about GPT-4 is how well it can take information you've provided and then analyze it, answer questions about it, extrapolate from it, and use it to generate new things.  But I've found that for long threads, there's a relatively narrow window after which it "forgets" what you've told it.  I don't know if it's accurately able to self report, but when asking ChatGPT about this, it claims that as a conversation goes on, it effectively forgets anything from far enough back in the conversation.

That's both interesting and unfortunate, but it does speak to the importance of training a lot of hyper-specific ChatGPT threads, because if you "change the subject" too much then it will no longer remember a lot of its previous context.

I'll have to see how this affects threads where I trained it to give a type of response and then keep asking it to do that thing over and over again.  I'm guessing that will keep working, since the context remains the same.  Whereas if I start one thread trying to train it to generate character names and then in the same thread have it try to generate place names, then that might eventually fail and have it forget its earlier context.

Very interesting, but important to remember.  On the plus side, this is a big area for future improvement which probably doesn't require another huge leap forward in the underlying GPT.  I'm guessing they could tune the existing algorithm to Just Work for this kind of use case by having it prioritize things said in a single conversation thread more highly than its original training data, though I don't actually know if that's true since I haven't read up on the underlying tech yet.

This directory contains notes grouped so as to help me copy/paste chunks of text which aren't too large for Google Bard or ChatGPT or whatever other AI systems come along in the next few years.  There isn't any information in any of these files which isn't already in other public pages either here in Github or on an Obsidian Portal wiki page somewhere, so this directory should be safe for humans to ignore unless they want to try using it to train their own ChatGPT threads or equivalent.
